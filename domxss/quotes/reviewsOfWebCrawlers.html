<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ReviewsOfWebCrawlers</title>
    <link rel="stylesheet" type="text/css" href="../../styles/sommaire.css">
</head>

<body>
    <div class="quotes">
        <h2><a href="domxsspapers/crawlers/crawlersReview.pdf" target="_blank"> ========= Untangling The Web Of XSS ========= </a></h2>
        <ol>
            <li>"The major types of web crawlers are generic deep web crawlers, focused crawlers and forum crawlers. Many crawlers have been developed which belong to these three categories. All these types of crawlers will start crawling from a single uniform resource locator (URL) called the ‘seed URL’."</li>
            <li>"There are two major issues that a web crawler has to deal with. A web page will contain <strong>so many links that are duplicate and leading to uninformative pages which a web crawler has to identify and ignore</strong>. Moreover, there can be <strong>‘spider traps’</strong> which may result in indefinite crawling and unlimited consumption of system resources"</li>
            <li>"T<a href="https://en.wikipedia.org/wiki/Breadth-first_search">BF</a>C uses a strategy in which the root node is crawled first. After that its successors are crawled. Then their successors are crawled and so on. This continues until all the nodes are crawled at a given depth in the search tree."</li>
            <li>"(regarding TBFC) it will start <strong>losing its focus</strong> which will result in the introduction of <strong>a lot of noise</strong> into the final collection. It may crawl many redundant and duplicate pages and may miss many useful pagesDownload of large amount of useless pages <strong>wastes network bandwidth and negatively affects repository quality</strong>. It crawls the pages <strong>without understanding the correlation among them</strong> and so it cannot be used to crawl web forums (Leng et al., 2011)."</li>
            <li>"Compared to the generic deep web crawler, focused crawlers yield good recall and precision by restricting themselves to a limited domain"</li>
            <li>"Another limitation is that increasing and decreasing threads for bandwidth management is a tedious task (Dey et al., 2010)."</li>
            <li>""</li>
            <li>""</li>
        </ol>
    </div>
</body>

</html>